{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. MODELLING\n",
    "***\n",
    "\n",
    "In this section we will create a recommendation system using the datasets to solve our main problem.\n",
    "There are different types of recomentation models, in this project we will focus on three types of recommentation systems\n",
    "\n",
    "* 1. Content-Based Recommender systems\n",
    "* 2. Collaborative Filtering Systems\n",
    "* 3. Deep Neural Networks\n",
    "\n",
    "Now, in each of these categories we will compare the different models and see which ones perform best. For validation and comparison we will use the RMSE (root mean squared error) metric, that is how far is the prediction from the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Text processing \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Machine learning and model selection\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import Dataset, Reader, SVD, accuracy, NormalPredictor,NMF\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split \n",
    "\n",
    "# Deep learning with TensorFlow\n",
    "from tensorflow.keras import models, layers, optimizers, losses, regularizers, metrics\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "\n",
    "# Utility functions\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Custom imports\n",
    "from classes.understanding import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. CONTENT BASED FILTERING\n",
    "***\n",
    "To perfrom the content based filtering, we utilized the restaurant data dataset.\n",
    "\n",
    "The restaurant's features such as types of cuisine they offer and attribues such as WiFi, Alcohol, Happy Hour, Noise Level, Restaurants Attire, Wheelchair Accessible, Restaurants TableService etc, were able to provide information to use cosine similarity to recommend the restaurants with the closest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38528 entries, 2 to 52285\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   business_id      38528 non-null  object \n",
      " 1   name             38528 non-null  object \n",
      " 2   address          38528 non-null  object \n",
      " 3   city             38528 non-null  object \n",
      " 4   state            38528 non-null  object \n",
      " 5   postal_code      38528 non-null  object \n",
      " 6   latitude         38528 non-null  float64\n",
      " 7   longitude        38528 non-null  float64\n",
      " 8   stars            38528 non-null  float64\n",
      " 9   review_count     38528 non-null  int64  \n",
      " 10  is_open          38528 non-null  int64  \n",
      " 11  attributes       38528 non-null  object \n",
      " 12  categories       38528 non-null  object \n",
      " 13  hours            38528 non-null  object \n",
      " 14  location         38528 non-null  object \n",
      " 15  attributes_true  38528 non-null  object \n",
      "dtypes: float64(3), int64(2), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loading the restaurant data from the pickled file\n",
    "df = pd.read_pickle('pickled_files/restaurants_data.pkl')\n",
    "\n",
    "# Overview of dataset information to understand the features we require\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Function to preprocess the data to combine the needed features into one column\n",
    "    Returns a dataframe with the combined_features columns\n",
    "    \"\"\"\n",
    "    filtered_df=df.copy()\n",
    "    # Combining the features into one column\n",
    "    filtered_df['combined_features'] = (\n",
    "                                        filtered_df['attributes'] + \" \" +\n",
    "                                        filtered_df['attributes_true'] \n",
    "                                        )\n",
    "    # resetting the index\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "    # Return turns the filtered df\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization function\n",
    "def create_feature_vectors(df):\n",
    "    \"\"\"\n",
    "    Performing vectorization of the preprocessed categorical features \n",
    "    and combining with the numerical features\n",
    "    \"\"\"\n",
    "    # Vectorize the combined text features\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(df['combined_features'])\n",
    "    \n",
    "    # Combine the TF-IDF matrix with numerical columns\n",
    "    numerical_features = df[['stars']].values\n",
    "    combined_features = np.hstack((tfidf_matrix.toarray(), numerical_features))\n",
    "    \n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the cosine similarity matrix we will now create a content-based recommendation system that offers recommendations to users based on the restaurant names or text words representing the specifications of their desired restaurant and attributes.\n",
    "\n",
    "We use the cosine similarity matrix to compare similarities between different restaurants and the customer's preferences, then pick the top n similar restaurants to recommend based on his/her input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation function\n",
    "def recommendation(df, state, name=None, category=None):\n",
    "    \"\"\"\n",
    "    Creates recommendation based on name or category/cuisine using cosine similarity and filtering\n",
    "    Returns a dataframe containing name, state, city, address, stars and categories\n",
    "    \"\"\"\n",
    "    preprocessed = preprocess(df)\n",
    "    \n",
    "    def cuisines(cuisine=None, state=state):\n",
    "        \"\"\"\n",
    "        Function to filter to get the recommendations based on cuisine input\n",
    "        \"\"\"\n",
    "        preprocessed=df[df[\"state\"]==state]\n",
    "        cuisine_df = preprocessed[preprocessed['categories'] == cuisine]\n",
    "        cuisine_df_sorted = cuisine_df.sort_values(by=[\"stars\", \"city\"], ascending=False)\n",
    "        return cuisine_df_sorted[['name', 'state', 'city', 'stars', 'address', 'categories']]\n",
    "    \n",
    "    if name:\n",
    "        if name not in preprocessed['name'].values:\n",
    "            raise ValueError(f\"Restaurant with name '{name}' not found in the filtered data.\")\n",
    "\n",
    "        # Finding the index of the restaurant name\n",
    "        idx = preprocessed[preprocessed['name'] == name].index[0]\n",
    "        exclude_names = [name]\n",
    "\n",
    "        # Locating the restaurant row in the preprocessed df \n",
    "        row_to_add = preprocessed.iloc[idx]\n",
    "        \n",
    "        # convering it to a df\n",
    "        row_to_add_df = pd.DataFrame([row_to_add])     \n",
    "        \n",
    "        #generating a df for only the state i want to recommend in\n",
    "        specific_state= preprocessed[preprocessed[\"state\"] == state]\n",
    "        \n",
    "        # concatinating it to the specific state df and reseting the index\n",
    "        specific_state = pd.concat([specific_state, row_to_add_df]).reset_index(drop=True)\n",
    "        \n",
    "        # Finding the new index for the restaurant name\n",
    "        idx = specific_state[specific_state['name'] == name].index[0]\n",
    "        \n",
    "        # Creating feature vectors\n",
    "        combined_features = create_feature_vectors(specific_state)\n",
    "\n",
    "        # Finding the cosine similarity\n",
    "        cosine_sim = cosine_similarity(combined_features, combined_features)\n",
    "\n",
    "        # Finding the top indices of the restaurants to recommend\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        top_indices = [i[0] for i in sim_scores]  \n",
    "\n",
    "        # Finding the rows of the top recommended restaurants\n",
    "        recommended_restaurants = specific_state.iloc[top_indices]\n",
    "        recommended_restaurants = recommended_restaurants[~recommended_restaurants['name'].isin(exclude_names)]        \n",
    "\n",
    "        # Return a df with the required features\n",
    "        return recommended_restaurants[['name', 'state', 'city', 'stars', 'address','categories']].drop_duplicates(subset='name')[:20]\n",
    "    \n",
    "    elif category:\n",
    "        # Filter based on cuisine/cateogry\n",
    "        return cuisines(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content_based function uses content-based recommendation techniques to provide restaurant recommendations based on user input preferences, restaurant names, or cuisine choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Restaurant Name: Bawarchi Biryani Point\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>location</th>\n",
       "      <th>attributes_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>8QeaCReOO-ryojndLvkBNg</td>\n",
       "      <td>Bawarchi Biryani Point</td>\n",
       "      <td>1516 Demonbreun St</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>37203</td>\n",
       "      <td>36.153262</td>\n",
       "      <td>-86.790054</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>{'RestaurantsGoodForGroups': 'True', 'GoodForK...</td>\n",
       "      <td>Indian</td>\n",
       "      <td>{'Monday': '11:0-21:30', 'Tuesday': '11:0-21:3...</td>\n",
       "      <td>State:Tennessee, City:Nashville, Address:1516 ...</td>\n",
       "      <td>RestaurantsGoodForGroups GoodForKids Restauran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18805</th>\n",
       "      <td>gtOVX8hGKKIryQs0lGPt3w</td>\n",
       "      <td>Bawarchi Biryani Point</td>\n",
       "      <td>2628 Kirkwood Hwy</td>\n",
       "      <td>Newark</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>19711</td>\n",
       "      <td>39.706175</td>\n",
       "      <td>-75.684116</td>\n",
       "      <td>3.5</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>{'OutdoorSeating': 'False', 'Ambience': \"{'tou...</td>\n",
       "      <td>Halal</td>\n",
       "      <td>{'Monday': '17:0-22:0', 'Wednesday': '17:0-22:...</td>\n",
       "      <td>State:Delaware, City:Newark, Address:2628 Kirk...</td>\n",
       "      <td>AmbienceAmbience RestaurantsPriceRange2 Restau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18805</th>\n",
       "      <td>gtOVX8hGKKIryQs0lGPt3w</td>\n",
       "      <td>Bawarchi Biryani Point</td>\n",
       "      <td>2628 Kirkwood Hwy</td>\n",
       "      <td>Newark</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>19711</td>\n",
       "      <td>39.706175</td>\n",
       "      <td>-75.684116</td>\n",
       "      <td>3.5</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>{'OutdoorSeating': 'False', 'Ambience': \"{'tou...</td>\n",
       "      <td>Indian</td>\n",
       "      <td>{'Monday': '17:0-22:0', 'Wednesday': '17:0-22:...</td>\n",
       "      <td>State:Delaware, City:Newark, Address:2628 Kirk...</td>\n",
       "      <td>AmbienceAmbience RestaurantsPriceRange2 Restau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26171</th>\n",
       "      <td>6UyNeDQWiqt4GvVsRU1aEQ</td>\n",
       "      <td>Bawarchi Biryani Point</td>\n",
       "      <td>625 Bakers Bridge Ave, Ste 100</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>37067</td>\n",
       "      <td>35.958327</td>\n",
       "      <td>-86.805382</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Caters': 'True', 'RestaurantsTableService': ...</td>\n",
       "      <td>Indian</td>\n",
       "      <td>{'Monday': '11:0-21:30', 'Tuesday': '11:0-21:3...</td>\n",
       "      <td>State:Tennessee, City:Franklin, Address:625 Ba...</td>\n",
       "      <td>Caters RestaurantsPriceRange2 WiFi Restaurants...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id                    name  \\\n",
       "7798   8QeaCReOO-ryojndLvkBNg  Bawarchi Biryani Point   \n",
       "18805  gtOVX8hGKKIryQs0lGPt3w  Bawarchi Biryani Point   \n",
       "18805  gtOVX8hGKKIryQs0lGPt3w  Bawarchi Biryani Point   \n",
       "26171  6UyNeDQWiqt4GvVsRU1aEQ  Bawarchi Biryani Point   \n",
       "\n",
       "                              address       city      state postal_code  \\\n",
       "7798               1516 Demonbreun St  Nashville  Tennessee       37203   \n",
       "18805               2628 Kirkwood Hwy     Newark   Delaware       19711   \n",
       "18805               2628 Kirkwood Hwy     Newark   Delaware       19711   \n",
       "26171  625 Bakers Bridge Ave, Ste 100   Franklin  Tennessee       37067   \n",
       "\n",
       "        latitude  longitude  stars  review_count  is_open  \\\n",
       "7798   36.153262 -86.790054    3.0            33        0   \n",
       "18805  39.706175 -75.684116    3.5            53        1   \n",
       "18805  39.706175 -75.684116    3.5            53        1   \n",
       "26171  35.958327 -86.805382    4.0           155        1   \n",
       "\n",
       "                                              attributes categories  \\\n",
       "7798   {'RestaurantsGoodForGroups': 'True', 'GoodForK...     Indian   \n",
       "18805  {'OutdoorSeating': 'False', 'Ambience': \"{'tou...      Halal   \n",
       "18805  {'OutdoorSeating': 'False', 'Ambience': \"{'tou...     Indian   \n",
       "26171  {'Caters': 'True', 'RestaurantsTableService': ...     Indian   \n",
       "\n",
       "                                                   hours  \\\n",
       "7798   {'Monday': '11:0-21:30', 'Tuesday': '11:0-21:3...   \n",
       "18805  {'Monday': '17:0-22:0', 'Wednesday': '17:0-22:...   \n",
       "18805  {'Monday': '17:0-22:0', 'Wednesday': '17:0-22:...   \n",
       "26171  {'Monday': '11:0-21:30', 'Tuesday': '11:0-21:3...   \n",
       "\n",
       "                                                location  \\\n",
       "7798   State:Tennessee, City:Nashville, Address:1516 ...   \n",
       "18805  State:Delaware, City:Newark, Address:2628 Kirk...   \n",
       "18805  State:Delaware, City:Newark, Address:2628 Kirk...   \n",
       "26171  State:Tennessee, City:Franklin, Address:625 Ba...   \n",
       "\n",
       "                                         attributes_true  \n",
       "7798   RestaurantsGoodForGroups GoodForKids Restauran...  \n",
       "18805  AmbienceAmbience RestaurantsPriceRange2 Restau...  \n",
       "18805  AmbienceAmbience RestaurantsPriceRange2 Restau...  \n",
       "26171  Caters RestaurantsPriceRange2 WiFi Restaurants...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a random restaurant name\n",
    "random_name = df['name'].sample(n=1).values[0]\n",
    "print(\"Random Restaurant Name:\", random_name)\n",
    "\n",
    "# Information on sampled restaurant\n",
    "df[df.name==random_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: Pennsylvania\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "      <th>address</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>Tabla Indian Cuisine</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Exton</td>\n",
       "      <td>3.0</td>\n",
       "      <td>290 E Lincoln Hwy</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9179</th>\n",
       "      <td>Soprano's Pizzeria &amp; Restaurant</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Warrington</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1380 Easton Rd</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>Maple Glen Pizza</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Maple Glen</td>\n",
       "      <td>3.0</td>\n",
       "      <td>641 E Welsh Rd</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Sicilian Trattoria</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Elkins Park</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7901 High School Rd</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>Ochatto Hot Pot</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3717 Chestnut St</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Capital Beer</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2661 E Cumberland St</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>PrimoHoagies</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Newtown</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2100 S Eagle Rd</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>Pho &amp; Cafe Viet Huong</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1110 Washington Ave, Ste 2A</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>Jade Harbor</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>3.0</td>\n",
       "      <td>942 Race St</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>Don Quixote Tapas &amp; Things</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>3.0</td>\n",
       "      <td>526 S 4th St</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name         state          city  stars  \\\n",
       "7953             Tabla Indian Cuisine  Pennsylvania         Exton    3.0   \n",
       "9179  Soprano's Pizzeria & Restaurant  Pennsylvania    Warrington    3.0   \n",
       "6574                 Maple Glen Pizza  Pennsylvania    Maple Glen    3.0   \n",
       "483                Sicilian Trattoria  Pennsylvania   Elkins Park    3.5   \n",
       "4803                  Ochatto Hot Pot  Pennsylvania  Philadelphia    3.5   \n",
       "659                      Capital Beer  Pennsylvania  Philadelphia    3.5   \n",
       "4086                     PrimoHoagies  Pennsylvania       Newtown    3.0   \n",
       "2672            Pho & Cafe Viet Huong  Pennsylvania  Philadelphia    3.5   \n",
       "3126                      Jade Harbor  Pennsylvania  Philadelphia    3.0   \n",
       "8516       Don Quixote Tapas & Things  Pennsylvania  Philadelphia    3.0   \n",
       "\n",
       "                          address  categories  \n",
       "7953            290 E Lincoln Hwy      Indian  \n",
       "9179               1380 Easton Rd     Italian  \n",
       "6574               641 E Welsh Rd     Italian  \n",
       "483           7901 High School Rd     Italian  \n",
       "4803             3717 Chestnut St     Chinese  \n",
       "659          2661 E Cumberland St     Chinese  \n",
       "4086              2100 S Eagle Rd     Italian  \n",
       "2672  1110 Washington Ave, Ste 2A  Vietnamese  \n",
       "3126                  942 Race St     Chinese  \n",
       "8516                 526 S 4th St     Spanish  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly chosen state\n",
    "random_state = df['state'].sample(n=1).values[0]\n",
    "print(\"Random State:\", random_state)\n",
    "\n",
    "# recommendations based on random state and random restaurant name\n",
    "restaurants = recommendation(df, state=random_state,  name=random_name)\n",
    "restaurants.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: Indiana\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "      <th>address</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Puccini's Pizza Pasta-Oaklandon</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7829 Sunnyside Rd</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>Puccini's Pizza Pasta - Fishers</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Fishers</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8993 E 116th St</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Mama's House</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8867 Pendleton Pike</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>Chipotle Mexican Grill</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Avon</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10403 E US Highway 36</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>El Arado Mexican Grill</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1063 Virginia Ave</td>\n",
       "      <td>Latin American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>QDOBA Mexican Eats</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Fishers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8971 E 116th St</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Los Rancheros</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7125 Georgetown Rd</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Blueberry Hill Pancake House</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7803 E Washington St</td>\n",
       "      <td>American (Traditional)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>The Egg &amp; I</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Carmel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2271 Pointe Pkwy, Ste 150</td>\n",
       "      <td>American (Traditional)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Puerto Vallarta Mexican Restaurant &amp; Cantina</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5510 Lafayette Rd</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name    state          city  \\\n",
       "1174               Puccini's Pizza Pasta-Oaklandon  Indiana  Indianapolis   \n",
       "2264               Puccini's Pizza Pasta - Fishers  Indiana       Fishers   \n",
       "762                                   Mama's House  Indiana  Indianapolis   \n",
       "1313                        Chipotle Mexican Grill  Indiana          Avon   \n",
       "85                          El Arado Mexican Grill  Indiana  Indianapolis   \n",
       "410                             QDOBA Mexican Eats  Indiana       Fishers   \n",
       "21                                   Los Rancheros  Indiana  Indianapolis   \n",
       "30                    Blueberry Hill Pancake House  Indiana  Indianapolis   \n",
       "170                                    The Egg & I  Indiana        Carmel   \n",
       "614   Puerto Vallarta Mexican Restaurant & Cantina  Indiana  Indianapolis   \n",
       "\n",
       "      stars                    address              categories  \n",
       "1174    3.5          7829 Sunnyside Rd                 Italian  \n",
       "2264    3.5            8993 E 116th St                 Italian  \n",
       "762     3.5        8867 Pendleton Pike              Vietnamese  \n",
       "1313    3.0      10403 E US Highway 36                 Mexican  \n",
       "85      3.0          1063 Virginia Ave          Latin American  \n",
       "410     3.0            8971 E 116th St                 Mexican  \n",
       "21      3.5         7125 Georgetown Rd                 Mexican  \n",
       "30      3.5       7803 E Washington St  American (Traditional)  \n",
       "170     3.0  2271 Pointe Pkwy, Ste 150  American (Traditional)  \n",
       "614     3.5          5510 Lafayette Rd                 Mexican  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly chosen state\n",
    "random_state = df['state'].sample(n=1).values[0]\n",
    "print(\"Random State:\", random_state)\n",
    "\n",
    "# recommendations based on random state and random restaurant name\n",
    "restaurants = recommendation(df, state=random_state,  name=random_name)\n",
    "restaurants.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "***\n",
    "\n",
    "- A randomly sampled restaurant name and a randomly sampled state were chosen for demostrational purposes.\n",
    "- It can be noted that, recommendation locations are accurate in that the restaurant may not be from that state but recommendations are given for the state in question.\n",
    "- We can also see that majority of the cuisines/categories match the restaurant in question.\n",
    "- Other attributes_true features contribute to the recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: Indiana\n",
      "Random Cuisine: Mediterranean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "      <th>address</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33196</th>\n",
       "      <td>Petos</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6020 E 82nd St, Ste 1411</td>\n",
       "      <td>Mediterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40909</th>\n",
       "      <td>Yannis Golden Gyros</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6658 W Washington St</td>\n",
       "      <td>Mediterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>The Palm Deli</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Zionsville</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10400 N Michigan Rd</td>\n",
       "      <td>Mediterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Bitter Sweet</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5543 E Washington St</td>\n",
       "      <td>Mediterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>Naf Naf Grill</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>4.5</td>\n",
       "      <td>921 Indiana Ave</td>\n",
       "      <td>Mediterranean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name    state          city  stars  \\\n",
       "33196                Petos  Indiana  Indianapolis    5.0   \n",
       "40909  Yannis Golden Gyros  Indiana  Indianapolis    5.0   \n",
       "2420         The Palm Deli  Indiana    Zionsville    4.5   \n",
       "734           Bitter Sweet  Indiana  Indianapolis    4.5   \n",
       "2430         Naf Naf Grill  Indiana  Indianapolis    4.5   \n",
       "\n",
       "                        address     categories  \n",
       "33196  6020 E 82nd St, Ste 1411  Mediterranean  \n",
       "40909      6658 W Washington St  Mediterranean  \n",
       "2420        10400 N Michigan Rd  Mediterranean  \n",
       "734        5543 E Washington St  Mediterranean  \n",
       "2430            921 Indiana Ave  Mediterranean  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = df['state'].sample(n=1).values[0]\n",
    "print(\"Random State:\", random_state)\n",
    "\n",
    "random_cuisine = df['categories'].sample(n=1).values[0]\n",
    "print(\"Random Cuisine:\", random_cuisine)\n",
    "\n",
    "# Example recommendations based on state, category/cuisine\n",
    "cuisines = recommendation(df, state=random_state,  category=random_cuisine)\n",
    "cuisines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "***\n",
    "- A randomly sampled state and a randomly sampled cuisine was used for demostration puposes\n",
    "- It can be seen that the system recommends the cuisine desired \n",
    "- As well as recommending specifically in the state desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### COLLABORATIVE FILTERING MODELS\n",
    "***\n",
    "\n",
    "Here the tasks related to building a collaborative filtering recommendation system using the Surprise library are undertaken for collaborative filtering by selecting the relevant columns, importing the Surprise library, initializing a Reader object to specify the data format, and then loading the data into a Surprise Dataset object for further analysis and model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2559586 entries, 0 to 2559585\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   user_id      object\n",
      " 1   business_id  object\n",
      " 2   stars        int64 \n",
      " 3   date         object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 78.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loading the users csv file\n",
    "users_data= pd.read_csv(\"data/users.csv\")\n",
    "\n",
    "# summary information on data\n",
    "users_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>location</th>\n",
       "      <th>attributes_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Melt</td>\n",
       "      <td>2549 Banks St</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>70119</td>\n",
       "      <td>29.962102</td>\n",
       "      <td>-90.087958</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BusinessParking': \"{'garage': False, 'street...</td>\n",
       "      <td>American (Traditional)</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...</td>\n",
       "      <td>State:Louisiana, City:New Orleans, Address:254...</td>\n",
       "      <td>BusinessParkingBusinessParking GoodForMealGood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RreNy--tOmXMl1en0wiBOg</td>\n",
       "      <td>cPepkJeRMtHapc_b2Oe_dw</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-17 03:30:07</td>\n",
       "      <td>Naked Tchopstix Express</td>\n",
       "      <td>2902 W 86th St, Ste 70</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>46268</td>\n",
       "      <td>39.912505</td>\n",
       "      <td>-86.211285</td>\n",
       "      <td>3.5</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>{'GoodForMeal': \"{'dessert': False, 'latenight...</td>\n",
       "      <td>Hawaiian</td>\n",
       "      <td>{'Monday': '11:0-21:0', 'Tuesday': '11:0-21:0'...</td>\n",
       "      <td>State:Indiana, City:Indianapolis, Address:2902...</td>\n",
       "      <td>OutdoorSeating RestaurantsTakeOut RestaurantsG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jha0USGDMefGFRLik_xFQg</td>\n",
       "      <td>bMratNjTG5ZFEA6hVyr-xQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-02-19 13:32:05</td>\n",
       "      <td>Portobello Cafe</td>\n",
       "      <td>1423 Chester Pike</td>\n",
       "      <td>Eddystone</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>19022</td>\n",
       "      <td>39.865032</td>\n",
       "      <td>-75.344051</td>\n",
       "      <td>4.0</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BikeParking': 'True', 'RestaurantsReservatio...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>{'Monday': '16:30-21:0', 'Tuesday': '16:30-21:...</td>\n",
       "      <td>State:Pennsylvania, City:Eddystone, Address:14...</td>\n",
       "      <td>BikeParking RestaurantsReservations HasTV Rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iYY5Ii1LGpZCpXFkHlMefw</td>\n",
       "      <td>Zx7n8mdt8OzLRXVzolXNhQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-04-27 23:03:21</td>\n",
       "      <td>Milk and Honey Nashville</td>\n",
       "      <td>214 11th Ave S</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>37203</td>\n",
       "      <td>36.154702</td>\n",
       "      <td>-86.784541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WheelchairAccessible': 'True', 'RestaurantsP...</td>\n",
       "      <td>American (Traditional)</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Thursday': '6:30-15:0',...</td>\n",
       "      <td>State:Tennessee, City:Nashville, Address:214 1...</td>\n",
       "      <td>WheelchairAccessible RestaurantsPriceRange2 Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S7bjj-L07JuRr-tpX1UZLw</td>\n",
       "      <td>I6L0Zxi5Ww0zEWSAVgngeQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-07 20:50:12</td>\n",
       "      <td>Cafe Beignet on Bourbon Street</td>\n",
       "      <td>311 Bourbon St</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>70130</td>\n",
       "      <td>29.955845</td>\n",
       "      <td>-90.068436</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1066</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GoodForKids': 'True', 'OutdoorSeating': 'Tru...</td>\n",
       "      <td>Cajun/Creole</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-15:0', '...</td>\n",
       "      <td>State:Louisiana, City:New Orleans, Address:311...</td>\n",
       "      <td>GoodForKids OutdoorSeating BusinessAcceptsCred...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  stars_x  \\\n",
       "0  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ        4   \n",
       "1  RreNy--tOmXMl1en0wiBOg  cPepkJeRMtHapc_b2Oe_dw        4   \n",
       "2  Jha0USGDMefGFRLik_xFQg  bMratNjTG5ZFEA6hVyr-xQ        5   \n",
       "3  iYY5Ii1LGpZCpXFkHlMefw  Zx7n8mdt8OzLRXVzolXNhQ        5   \n",
       "4  S7bjj-L07JuRr-tpX1UZLw  I6L0Zxi5Ww0zEWSAVgngeQ        4   \n",
       "\n",
       "                  date                            name  \\\n",
       "0  2017-01-14 20:54:15                            Melt   \n",
       "1  2018-07-17 03:30:07         Naked Tchopstix Express   \n",
       "2  2017-02-19 13:32:05                 Portobello Cafe   \n",
       "3  2018-04-27 23:03:21        Milk and Honey Nashville   \n",
       "4  2018-07-07 20:50:12  Cafe Beignet on Bourbon Street   \n",
       "\n",
       "                  address          city         state postal_code   latitude  \\\n",
       "0           2549 Banks St   New Orleans     Louisiana       70119  29.962102   \n",
       "1  2902 W 86th St, Ste 70  Indianapolis       Indiana       46268  39.912505   \n",
       "2       1423 Chester Pike     Eddystone  Pennsylvania       19022  39.865032   \n",
       "3          214 11th Ave S     Nashville     Tennessee       37203  36.154702   \n",
       "4          311 Bourbon St   New Orleans     Louisiana       70130  29.955845   \n",
       "\n",
       "   longitude  stars_y  review_count  is_open  \\\n",
       "0 -90.087958      4.0            32        0   \n",
       "1 -86.211285      3.5            33        0   \n",
       "2 -75.344051      4.0           137        1   \n",
       "3 -86.784541      4.0          1725        1   \n",
       "4 -90.068436      3.5          1066        1   \n",
       "\n",
       "                                          attributes              categories  \\\n",
       "0  {'BusinessParking': \"{'garage': False, 'street...  American (Traditional)   \n",
       "1  {'GoodForMeal': \"{'dessert': False, 'latenight...                Hawaiian   \n",
       "2  {'BikeParking': 'True', 'RestaurantsReservatio...                 Italian   \n",
       "3  {'WheelchairAccessible': 'True', 'RestaurantsP...  American (Traditional)   \n",
       "4  {'GoodForKids': 'True', 'OutdoorSeating': 'Tru...            Cajun/Creole   \n",
       "\n",
       "                                               hours  \\\n",
       "0  {'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...   \n",
       "1  {'Monday': '11:0-21:0', 'Tuesday': '11:0-21:0'...   \n",
       "2  {'Monday': '16:30-21:0', 'Tuesday': '16:30-21:...   \n",
       "3  {'Monday': '0:0-0:0', 'Thursday': '6:30-15:0',...   \n",
       "4  {'Monday': '0:0-0:0', 'Tuesday': '8:0-15:0', '...   \n",
       "\n",
       "                                            location  \\\n",
       "0  State:Louisiana, City:New Orleans, Address:254...   \n",
       "1  State:Indiana, City:Indianapolis, Address:2902...   \n",
       "2  State:Pennsylvania, City:Eddystone, Address:14...   \n",
       "3  State:Tennessee, City:Nashville, Address:214 1...   \n",
       "4  State:Louisiana, City:New Orleans, Address:311...   \n",
       "\n",
       "                                     attributes_true  \n",
       "0  BusinessParkingBusinessParking GoodForMealGood...  \n",
       "1  OutdoorSeating RestaurantsTakeOut RestaurantsG...  \n",
       "2  BikeParking RestaurantsReservations HasTV Rest...  \n",
       "3  WheelchairAccessible RestaurantsPriceRange2 Bu...  \n",
       "4  GoodForKids OutdoorSeating BusinessAcceptsCred...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging the two datasets into one using the business_id primary key\n",
    "data=pd.merge(left=users_data, right=df, how='inner', on='business_id')\n",
    "\n",
    "# previewing the new merge dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2386719 entries, 0 to 2386718\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   user_id          object \n",
      " 1   business_id      object \n",
      " 2   b/s_rating       int64  \n",
      " 3   date             object \n",
      " 4   name             object \n",
      " 5   address          object \n",
      " 6   city             object \n",
      " 7   state            object \n",
      " 8   postal_code      object \n",
      " 9   latitude         float64\n",
      " 10  longitude        float64\n",
      " 11  rating           float64\n",
      " 12  review_count     int64  \n",
      " 13  is_open          int64  \n",
      " 14  attributes       object \n",
      " 15  categories       object \n",
      " 16  hours            object \n",
      " 17  location         object \n",
      " 18  attributes_true  object \n",
      "dtypes: float64(3), int64(3), object(13)\n",
      "memory usage: 346.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Renaming the **stars_x** and **stars_y** columns into **rating** and **b/s_rating** columns for better understanding\n",
    "data.rename(columns={'stars_x':'b/s_rating', 'stars_y':'rating'}, inplace=True)\n",
    "\n",
    "# previewing the data information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocessing Data For Modeling**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  738495 \n",
      "\n",
      "Number of Restaurants:  24835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#selecting specific columns that are relevant for collaborative filtering models\n",
    "new_df = data[['user_id', 'business_id', 'rating']]\n",
    "\n",
    "# using Reader() from surprise module to convert dataframe into surprise dataformat\n",
    "# instantiating a reader object\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# using the reader to read the trainset\n",
    "data_2 = Dataset.load_from_df(new_df,reader)\n",
    "\n",
    "# Creating a train set with all available data\n",
    "dataset = data_2.build_full_trainset()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "trainset, testset = train_test_split(data_2, test_size=0.25)\n",
    "\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of Restaurants: ', dataset.n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('data/new_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Baseline Model Using Normal Predictor**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8192241778434399"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Normal Predictor algorithm\n",
    "model_1 = NormalPredictor()\n",
    "\n",
    "# Train the model on the training set\n",
    "model_1.fit(trainset)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "predictions = model_1.test(testset)\n",
    "\n",
    "# Compute rmse\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "***\n",
    "- A normal predictor model from the surpise library was used as the initial dummy prediction model\n",
    "- The model was able to achieve an RMSE of 0.819 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NMF Model With Default Parameters**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3489352110051806"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVD algorithm\n",
    "model_2 = NMF(random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "model_2.fit(trainset)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "predictions = model_2.test(testset)\n",
    "\n",
    "# Compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "***\n",
    "- A Non-Negative Matrix Factorization(NMF) model was used as it is ideal when ratings are non-negative (i.e., ratings from 1 to 5).\n",
    "- The model was able to achieve an RMSE of 0.3495 which was a great improvement on the Normal Predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVD Model With Default Parameters**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11709911789888452"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVD algorithm\n",
    "model_3 = SVD(random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "model_3.fit(trainset)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "predictions = model_3.test(testset)\n",
    "\n",
    "# Compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.11434558, 0.11308608, 0.11462078, 0.1136382 , 0.11273292]))\n",
      "('test_mae', array([0.05442948, 0.05430722, 0.05431262, 0.05436357, 0.05414083]))\n",
      "('fit_time', (50.03808856010437, 52.460954666137695, 45.77838850021362, 39.04082918167114, 34.15108132362366))\n",
      "('test_time', (10.056745052337646, 8.097829580307007, 7.090398073196411, 5.896436929702759, 5.190059661865234))\n",
      "-------------------------\n",
      "Mean RMSE:  0.11368471505593795\n"
     ]
    }
   ],
   "source": [
    "# using cross-validate to get the test rmse scores for 5 splits\n",
    "results=cross_validate(model_3, data_2, cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "for values in results.items():\n",
    "    print(values)\n",
    "print(\"-------------------------\")\n",
    "print(\"Mean RMSE: \",results['test_rmse'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "***\n",
    "- A Singe value Decomposition(SVD) model was used as it works well with explicit feedback (i.e. ratings)\n",
    "- The model was able to achieve an RMSE of 0.119 which further improved the RMSE\n",
    "- The model was then cross validated and ahcieved an RMSE mean of 0.113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameter Tuning SVD model**\n",
    "***\n",
    "Hyperparameter tuning was carried out using grid search and cross-validation. It tests different values of the number of latent factors (n_factors),regularization term (reg_all) and the number of epochs (n_epochs) to find the combination that results in the best model performance. The final best hyperparameters can be accessed from the g_s_svd object for use in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary params with hyperparameter values to be tested\n",
    "params = {'n_factors': [20, 50, 100], \n",
    "         'reg_all': [00.01, .02, 0.05],\n",
    "         'n_epochs':[20,30,40]} \n",
    "\n",
    "# create a GridSearchCV object 'g_s_svd' for hyperparameter tuning\n",
    "g_s_svd = GridSearchCV(SVD,param_grid=params,n_jobs=-1) \n",
    "\n",
    "# fit the GridSearchCV object to the data to find the best hyperparameters\n",
    "g_s_svd.fit(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.06584980717002013, 'mae': 0.026864421536656607}\n",
      "{'rmse': {'n_factors': 20, 'reg_all': 0.01, 'n_epochs': 40}, 'mae': {'n_factors': 20, 'reg_all': 0.01, 'n_epochs': 40}}\n"
     ]
    }
   ],
   "source": [
    "print(g_s_svd.best_score)\n",
    "print(g_s_svd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0683430536959298"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting optimal parameters\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "model_4 = SVD(n_factors= 20, reg_all=0.01, n_epochs = 40)\n",
    "\n",
    "# Train the model on the training set\n",
    "model_4.fit(trainset)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "predictions = model_4.test(testset)\n",
    "\n",
    "# Compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model into a pickle\n",
    "with open('pickled_files/svd.pkl', 'wb') as file:\n",
    "    pickle.dump(model_4, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "***\n",
    "\n",
    "The RMSE value for the optimized SVD model is approximately 0.0683, indicating the model's average prediction error in terms of user ratings. Lower RMSE values are desirable as they signify better predictive accuracy.                              \n",
    "                                           \n",
    "The best-performing hyperparameter values are as follows:                       \n",
    "For optimal RMSE, the optimal hyperparameters are 'n_factors' = 20,'reg_all' = 0.01 and 'n_epochs': 40.\n",
    "  \n",
    "These results indicate that the SVD collaborative filtering model, when configured with these hyperparameters, provides a relatively low prediction error and is well-suited for making personalized recommendations based on user ratings.\n",
    "\n",
    "This model was then saved in a pickle file for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborative filtering Intergration**\n",
    "***\n",
    "\n",
    "\n",
    "This below  allows a user to interactively rate restaurants by providing their ratings for a specified number of restaurants, and it collects this information in a list for further analysis or use in a recommendation system. The code also considers the restaurant category for selecting restaurants to rate if a category is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_ratings(df, state, num_samples=5, max_ratings=3):\n",
    "    \"\"\"\n",
    "    Function to collect ratings for a number of randomly sampled restaurants.\n",
    "    Allows users to skip restaurants they have never been to and limits the total number of final ratings to a specified maximum.\n",
    "    \"\"\"\n",
    "    ratings = []\n",
    "\n",
    "    while len(ratings) < max_ratings:\n",
    "        # Sampling the specified number of restaurants\n",
    "        filtered_df=df[df.state==state]\n",
    "\n",
    "        sampled_restaurants = filtered_df.sample(n=num_samples)\n",
    "        \n",
    "        for _, row in sampled_restaurants.iterrows():\n",
    "            restaurant_id = row['business_id']\n",
    "            restaurant_name = row['name']\n",
    "            restaurant_state=row[\"state\"]\n",
    "            restaurant_city =row[\"city\"]\n",
    "\n",
    "            while True:\n",
    "                # Ask if the user has been to the restaurant\n",
    "                been_to_restaurant = input(f\"Have you been to {restaurant_name}, {restaurant_state},{restaurant_city}? (y/n): \").strip().lower()\n",
    "                \n",
    "                if been_to_restaurant == 'n':\n",
    "                    print(f\"Skipping {restaurant_name}.\")\n",
    "                    break  \n",
    "                \n",
    "                elif been_to_restaurant == 'y':\n",
    "                    while True:\n",
    "                        try:\n",
    "                            # Prompt user for rating\n",
    "                            print(f\"Please rate {restaurant_name} on a scale of 1 to 5:\")\n",
    "                            rating = int(input())\n",
    "                            \n",
    "                            # Check if the rating is within the valid range\n",
    "                            if 1 <= rating <= 5:\n",
    "                                print(f\"Rating for {restaurant_name}: {rating}\")\n",
    "                                ratings.append((restaurant_id, rating))\n",
    "                                \n",
    "                                # Check if we have reached the maximum number of ratings\n",
    "                                if len(ratings) >= max_ratings:\n",
    "                                    print(\"Maximum number of ratings collected.\")\n",
    "                                    return ratings\n",
    "                                \n",
    "                                break  \n",
    "                            else:\n",
    "                                print(\"Rating must be between 1 and 5. Please try again.\")\n",
    "                        except ValueError:\n",
    "                            print(\"Invalid input. Please enter a number between 1 and 5.\")\n",
    "                    break  \n",
    "                \n",
    "                else:\n",
    "                    print(\"Please answer 'yes' or 'no'.\")\n",
    "                \n",
    "        # If not enough ratings are collected, continue sampling\n",
    "        print(f\"Collected {len(ratings)} ratings so far. Collecting more samples.\")\n",
    "\n",
    "    return ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_restaurants(user_id, rated_restaurants, all_restaurants_df=df, state=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to recommend restaurants based on state. the rated restaurnats are concatenated to the new_df dataframe, a model is created\n",
    "    the rated restaurants are filtered from the unrated restaurants and prediction is performed. the resulting dataframe is sorted by highest \n",
    "    predicted ratings \n",
    "    \"\"\"\n",
    "    # Filter by state if provided\n",
    "    all_restaurants_df = all_restaurants_df[all_restaurants_df[\"state\"] == state]\n",
    "\n",
    "    # Get all restaurant IDs\n",
    "    all_restaurant_ids = all_restaurants_df['business_id'].unique()\n",
    "\n",
    "    # Prepare the data for training the model\n",
    "    # Create DataFrame for the user's ratings\n",
    "    user_ratings_df = pd.DataFrame(rated_restaurants, columns=['business_id', 'rating'])\n",
    "    user_ratings_df['user_id'] = user_id  \n",
    "\n",
    "    # Combine user-specific ratings with the full dataset\n",
    "    combined_df = pd.concat([new_df, user_ratings_df])\n",
    "\n",
    "    # Filter combined_df to include only relevant restaurants\n",
    "    filtered_df = combined_df[combined_df['business_id'].isin(all_restaurant_ids)]\n",
    "\n",
    "    # Define the Reader and Dataset\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(filtered_df[['user_id', 'business_id', 'rating']], reader)\n",
    "\n",
    "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    # trainset = data.build_full_trainset()\n",
    "\n",
    "    # Retrain the model\n",
    "    model_4 = SVD(n_factors= 20, reg_all=0.01, n_epochs = 40, random_state=42)\n",
    "    model_4.fit(trainset)\n",
    "\n",
    "    # Filter out the restaurants that the user has already rated\n",
    "    rated_restaurant_ids = [rid for rid, _ in rated_restaurants]\n",
    "    unrated_restaurants = [rid for rid in all_restaurant_ids if rid not in rated_restaurant_ids]\n",
    "\n",
    "    # Predict ratings for all unrated restaurants\n",
    "    predictions = [model_4.predict(user_id, rid) for rid in unrated_restaurants]\n",
    "\n",
    "    # Create a DataFrame for the predictions\n",
    "    pred_df = pd.DataFrame({\n",
    "        'business_id': [pred.iid for pred in predictions],\n",
    "        'predicted_rating': [pred.est for pred in predictions]\n",
    "    })\n",
    "\n",
    "    # Merge with the original restaurants DataFrame to get more information\n",
    "    recommendations = pred_df.merge(all_restaurants_df, on='business_id', how='left')\n",
    "\n",
    "    # Sort by predicted rating and get top recommendations\n",
    "    recommendations = recommendations.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be asked to rate 5 random restaurants.\n",
      "Please answer 'yes' or 'no'.\n",
      "Please answer 'yes' or 'no'.\n",
      "Please rate Ambrosia Ristorante BYOB on a scale of 1 to 5:\n",
      "Rating for Ambrosia Ristorante BYOB: 4\n",
      "Please rate Dave & Buster's on a scale of 1 to 5:\n",
      "Rating for Dave & Buster's: 4\n",
      "Please rate Pizzeria Nonna on a scale of 1 to 5:\n",
      "Rating for Pizzeria Nonna: 1\n",
      "Maximum number of ratings collected.\n",
      "[('-Ti5pwj6mA99khsxxur8aQ', 4), ('Gr6nYrQ_-3p4LcE4M84lTw', 4), ('aca4m9TSqTxQsEQ2H0KSwA', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Collect ratings from the user\n",
    "print(\"You will be asked to rate 5 random restaurants.\")\n",
    "user_ratings = collect_ratings(df, state=\"Pennsylvania\")\n",
    "print(user_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "      <th>location</th>\n",
       "      <th>attributes_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>lBHZc-fGzL8fRWREy7VlZA</td>\n",
       "      <td>1.036582</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>2422 W Passyunk Avenue</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>19145</td>\n",
       "      <td>39.922100</td>\n",
       "      <td>-75.187260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>{'DriveThru': 'True', 'RestaurantsPriceRange2'...</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>{'Monday': '10:30-0:0', 'Tuesday': '10:30-0:0'...</td>\n",
       "      <td>State:Pennsylvania, City:Philadelphia, Address...</td>\n",
       "      <td>DriveThru RestaurantsPriceRange2 RestaurantsDe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>zm4TZxLGRbGkhfw_aaMwnQ</td>\n",
       "      <td>1.197435</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1084 E Lancaster Ave</td>\n",
       "      <td>Rosemont</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>19010</td>\n",
       "      <td>40.026275</td>\n",
       "      <td>-75.328725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>{'RestaurantsTableService': 'False', 'Business...</td>\n",
       "      <td>Italian</td>\n",
       "      <td>{'Monday': '11:0-23:0', 'Tuesday': '11:0-23:0'...</td>\n",
       "      <td>State:Pennsylvania, City:Rosemont, Address:108...</td>\n",
       "      <td>BusinessAcceptsCreditCards RestaurantsAttire A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>sCPx4Sy4I1wMeZwsTzCFRg</td>\n",
       "      <td>1.307281</td>\n",
       "      <td>Chipotle Mexican Grill</td>\n",
       "      <td>1000 S Broad St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>19146</td>\n",
       "      <td>39.938642</td>\n",
       "      <td>-75.166875</td>\n",
       "      <td>1.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'True', 'BusinessParki...</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '10:45-22:0',...</td>\n",
       "      <td>State:Pennsylvania, City:Philadelphia, Address...</td>\n",
       "      <td>RestaurantsDelivery RestaurantsTakeOut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  predicted_rating                    name  \\\n",
       "4543  lBHZc-fGzL8fRWREy7VlZA          1.036582               Taco Bell   \n",
       "6590  zm4TZxLGRbGkhfw_aaMwnQ          1.197435               Pizza Hut   \n",
       "1406  sCPx4Sy4I1wMeZwsTzCFRg          1.307281  Chipotle Mexican Grill   \n",
       "\n",
       "                     address          city         state postal_code  \\\n",
       "4543  2422 W Passyunk Avenue  Philadelphia  Pennsylvania       19145   \n",
       "6590    1084 E Lancaster Ave      Rosemont  Pennsylvania       19010   \n",
       "1406         1000 S Broad St  Philadelphia  Pennsylvania       19146   \n",
       "\n",
       "       latitude  longitude  stars  review_count  is_open  \\\n",
       "4543  39.922100 -75.187260    1.0            17        1   \n",
       "6590  40.026275 -75.328725    1.0            18        0   \n",
       "1406  39.938642 -75.166875    1.5            24        1   \n",
       "\n",
       "                                             attributes categories  \\\n",
       "4543  {'DriveThru': 'True', 'RestaurantsPriceRange2'...    Mexican   \n",
       "6590  {'RestaurantsTableService': 'False', 'Business...    Italian   \n",
       "1406  {'RestaurantsDelivery': 'True', 'BusinessParki...    Mexican   \n",
       "\n",
       "                                                  hours  \\\n",
       "4543  {'Monday': '10:30-0:0', 'Tuesday': '10:30-0:0'...   \n",
       "6590  {'Monday': '11:0-23:0', 'Tuesday': '11:0-23:0'...   \n",
       "1406  {'Monday': '0:0-0:0', 'Tuesday': '10:45-22:0',...   \n",
       "\n",
       "                                               location  \\\n",
       "4543  State:Pennsylvania, City:Philadelphia, Address...   \n",
       "6590  State:Pennsylvania, City:Rosemont, Address:108...   \n",
       "1406  State:Pennsylvania, City:Philadelphia, Address...   \n",
       "\n",
       "                                        attributes_true  \n",
       "4543  DriveThru RestaurantsPriceRange2 RestaurantsDe...  \n",
       "6590  BusinessAcceptsCreditCards RestaurantsAttire A...  \n",
       "1406             RestaurantsDelivery RestaurantsTakeOut  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entering user_id\n",
    "user_id = 'uu1651'\n",
    "\n",
    "# Recommendation based on state and ratings\n",
    "recommended_restaurants = recommend_restaurants(user_id=user_id, rated_restaurants=user_ratings, state= \"Pennsylvania\").drop_duplicates(subset='name')\n",
    "\n",
    "# Viewing the top 5 entries\n",
    "recommended_restaurants.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the implementaion of collaborative filtering to be effective, it is highly dependent on the state from which you would choose to rate th restaurants. This is shown using the example above\n",
    "\n",
    "If you are from Pennsylvania state, Philadelphia city, you would receive rating requests for the state of Pennsylvania. It is possible to skip to only rate restaurants in Philadelphia city only.\n",
    "\n",
    "The user would have to rate at least 3 restaurants to be able to get recommendations\n",
    "\n",
    "These ratings would then be passed through an SVD model to predict all the unrated restaurants giving a predicted rating\n",
    "\n",
    "This predicted rating is then sorted in descending order and used to give a list of all recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### NEURAL NETWORKS MODEL\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run a Keras deep neural network to implement a recommendation system and try to improve our RMSE scores by using neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We are going to encode the user_id and business_id features into numeric integers in preparation for the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users:  220872\n",
      "Number of Restaurants:  31834\n"
     ]
    }
   ],
   "source": [
    "# Encoding the user_id column\n",
    "user_encoder = LabelEncoder()                                    # instantiating the encoder\n",
    "data['userId'] = user_encoder.fit_transform(data.user_id.values) # fitting and transforming the encoder to our column\n",
    "n_users=data['userId'].nunique()                                 # assigning the number of users to n_user vaiable\n",
    "print(\"Number of Users: \",n_users)\n",
    "\n",
    "# Encoding the business_id column\n",
    "item_encoder = LabelEncoder()                                          # instantiating the encoder\n",
    "data['restId'] = user_encoder.fit_transform(data.business_id.values)   # fitting and transforming the encoder to our column\n",
    "n_rests = data['restId'].nunique()                                  # assigning the number of restaurants to n_rests vaiable\n",
    "print(\"Number of Restaurants: \",n_rests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Splitting the data into training and testing sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428157, 2) (428157,)\n",
      "(107040, 2) (107040,)\n"
     ]
    }
   ],
   "source": [
    "# subsetting the x variable\n",
    "X = data[['userId', 'restId']].values\n",
    "# subsetting the y variable\n",
    "y = data['rating'].values\n",
    "\n",
    "# creating the train test splits and stratifying on basis of the y values \n",
    "# because of the uneven nature of the rating counts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculate the minimum and maximum ratings, which will be used to scale the output of the neural network later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum rating\n",
    "min_rating = min(data['rating'])\n",
    "max_rating = max(data['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The predicted ratings is calculated by multiplying the user and restaurant embeddings, then adding the user and restaurant bias. Therefore were are going to create user and restaurant embeddings together with bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of latent factors\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Defining user embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User embeddings\n",
    "\n",
    "# user input layer\n",
    "user = layers.Input(shape=(1,))\n",
    "\n",
    "# Embedding layer for calculating user latent factors of size 50\n",
    "user_emb = layers.Embedding(n_users, embedding_size, embeddings_regularizer=regularizers.l2(1e-6))(user)\n",
    "\n",
    "# Reshaping the layer to flatten the embedding vector.\n",
    "user_emb = layers.Reshape((embedding_size,))(user_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Defining user bias, and reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User bias\n",
    "\n",
    "# Embedding layer\n",
    "user_bias = layers.Embedding(n_users, 1, embeddings_regularizer=regularizers.l2(1e-6))(user)\n",
    "\n",
    "# Reshapin the user bias layer\n",
    "user_bias = layers.Reshape((1,))(user_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Defining restaurants embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurant embeddings\n",
    "\n",
    "# Input layer\n",
    "restaurant= layers.Input(shape=(1,))\n",
    "\n",
    "# Embedding layer\n",
    "rest_emb = layers.Embedding(n_rests, embedding_size, embeddings_regularizer=regularizers.l2(1e-6))(restaurant)\n",
    "\n",
    "# Reshape layer\n",
    "rest_emb = layers.Reshape((embedding_size,))(rest_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Defining restaurant bias, and reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restaurant bias\n",
    "\n",
    "# Embedding layer\n",
    "rest_bias = layers.Embedding(n_rests, 1, embeddings_regularizer=regularizers.l2(1e-6))(restaurant)\n",
    "\n",
    "# Reshape layer\n",
    "rest_bias = layers.Reshape((1,))(rest_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After defining the embedding and bias layers, the predicted rating is calculated by dot product of the user and restaurant embeddings and then adding the bias values in order to get more accurate ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product of the user and restaurant embeddings\n",
    "rating = layers.Concatenate()([user_emb, rest_emb])\n",
    "\n",
    "# Add biases to the ratings\n",
    "# Adding the user and restaurant bias to the predicted rating\n",
    "rating = layers.Add()([rating, user_bias, rest_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We move on to pass the calculated rating to layers of dense networks and finally converting the rating score from binary values into a range of 1-5. \n",
    "\n",
    "We create our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 146ms/step - loss: 2.2653 - root_mean_squared_error: 1.5015 - val_loss: 2.2630 - val_root_mean_squared_error: 1.5007\n",
      "Epoch 2/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 148ms/step - loss: 2.2557 - root_mean_squared_error: 1.4983 - val_loss: 2.2616 - val_root_mean_squared_error: 1.5003\n",
      "Epoch 3/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 138ms/step - loss: 2.2602 - root_mean_squared_error: 1.4998 - val_loss: 2.2623 - val_root_mean_squared_error: 1.5005\n",
      "Epoch 4/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 185ms/step - loss: 2.2639 - root_mean_squared_error: 1.5011 - val_loss: 2.2614 - val_root_mean_squared_error: 1.5002\n",
      "Epoch 5/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 157ms/step - loss: 2.2591 - root_mean_squared_error: 1.4994 - val_loss: 2.2607 - val_root_mean_squared_error: 1.5000\n",
      "Epoch 6/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 147ms/step - loss: 2.2514 - root_mean_squared_error: 1.4969 - val_loss: 2.2590 - val_root_mean_squared_error: 1.4994\n",
      "Epoch 7/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 140ms/step - loss: 2.2587 - root_mean_squared_error: 1.4993 - val_loss: 2.2549 - val_root_mean_squared_error: 1.4980\n",
      "Epoch 8/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 148ms/step - loss: 2.2457 - root_mean_squared_error: 1.4950 - val_loss: 2.2322 - val_root_mean_squared_error: 1.4905\n",
      "Epoch 9/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 180ms/step - loss: 2.1951 - root_mean_squared_error: 1.4780 - val_loss: 2.1834 - val_root_mean_squared_error: 1.4740\n",
      "Epoch 10/10\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 187ms/step - loss: 2.0870 - root_mean_squared_error: 1.4409 - val_loss: 2.1166 - val_root_mean_squared_error: 1.4512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f21fe2e3950>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# first dense layer of 30 nodes with relu activation\n",
    "rating = layers.Dense(30, activation='relu')(rating)\n",
    "\n",
    "# second dense layer of 15 nodes\n",
    "rating = layers.Dense(15, activation='relu')(rating)\n",
    "\n",
    "# output layer with one node that produces values between 0 and 1 due to the sigmoid activation\n",
    "rating = layers.Dense(1, activation='sigmoid')(rating)\n",
    "# rating= layers.Dense(5, activation='softmax')(rating)\n",
    "\n",
    "# Scales the predicted ratings to a range of 1 - 5\n",
    "rating = layers.Lambda(lambda x:x*(max_rating - min_rating) + min_rating)(rating)\n",
    "\n",
    "\n",
    "# Baseline Model \n",
    "baseline_model = models.Model([user, restaurant], rating)\n",
    "\n",
    "# Compile the model\n",
    "baseline_model.compile( optimizer='sgd', loss='mse',  metrics=[metrics.RootMeanSquaredError()])\n",
    "\n",
    "# training the model\n",
    "baseline_model .fit(x=[X_train[:,0], X_train[:,1]], y=y_train,\n",
    "                    batch_size=256, \n",
    "                    epochs=10, \n",
    "                    verbose=1,\n",
    "                    validation_data=([X_test[:,0], X_test[:,1]], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Our baseline model, does not overfit since the training RMSE score and the validation scores are not far off. We then proceed to tune the model in order to get better rmse scores, by reducing the model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 184ms/step - loss: 2.1169 - root_mean_squared_error: 1.4413 - val_loss: 2.0627 - val_root_mean_squared_error: 1.4232\n",
      "Epoch 2/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 153ms/step - loss: 1.8676 - root_mean_squared_error: 1.3530 - val_loss: 2.0022 - val_root_mean_squared_error: 1.4022\n",
      "Epoch 3/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 188ms/step - loss: 1.7143 - root_mean_squared_error: 1.2955 - val_loss: 1.9576 - val_root_mean_squared_error: 1.3865\n",
      "Epoch 4/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 180ms/step - loss: 1.5578 - root_mean_squared_error: 1.2340 - val_loss: 1.9376 - val_root_mean_squared_error: 1.3795\n",
      "Epoch 5/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 134ms/step - loss: 1.4274 - root_mean_squared_error: 1.1802 - val_loss: 1.9344 - val_root_mean_squared_error: 1.3785\n",
      "Epoch 6/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 119ms/step - loss: 1.3002 - root_mean_squared_error: 1.1252 - val_loss: 1.9345 - val_root_mean_squared_error: 1.3787\n",
      "Epoch 7/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 145ms/step - loss: 1.2128 - root_mean_squared_error: 1.0859 - val_loss: 1.9420 - val_root_mean_squared_error: 1.3817\n",
      "Epoch 8/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 146ms/step - loss: 1.1415 - root_mean_squared_error: 1.0529 - val_loss: 1.9400 - val_root_mean_squared_error: 1.3812\n",
      "Epoch 9/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 160ms/step - loss: 1.0845 - root_mean_squared_error: 1.0258 - val_loss: 1.9468 - val_root_mean_squared_error: 1.3839\n",
      "Epoch 10/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 151ms/step - loss: 1.0464 - root_mean_squared_error: 1.0074 - val_loss: 1.9494 - val_root_mean_squared_error: 1.3851\n",
      "Epoch 11/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 157ms/step - loss: 1.0143 - root_mean_squared_error: 0.9917 - val_loss: 1.9519 - val_root_mean_squared_error: 1.3863\n",
      "Epoch 12/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 163ms/step - loss: 0.9740 - root_mean_squared_error: 0.9716 - val_loss: 1.9518 - val_root_mean_squared_error: 1.3865\n",
      "Epoch 13/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 157ms/step - loss: 0.9467 - root_mean_squared_error: 0.9578 - val_loss: 1.9566 - val_root_mean_squared_error: 1.3885\n",
      "Epoch 14/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 147ms/step - loss: 0.9188 - root_mean_squared_error: 0.9436 - val_loss: 1.9643 - val_root_mean_squared_error: 1.3915\n",
      "Epoch 15/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 138ms/step - loss: 0.8866 - root_mean_squared_error: 0.9267 - val_loss: 1.9547 - val_root_mean_squared_error: 1.3883\n",
      "Epoch 16/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 139ms/step - loss: 0.8685 - root_mean_squared_error: 0.9172 - val_loss: 1.9573 - val_root_mean_squared_error: 1.3895\n",
      "Epoch 17/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 150ms/step - loss: 0.8411 - root_mean_squared_error: 0.9025 - val_loss: 1.9578 - val_root_mean_squared_error: 1.3899\n",
      "Epoch 18/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 149ms/step - loss: 0.8167 - root_mean_squared_error: 0.8893 - val_loss: 1.9564 - val_root_mean_squared_error: 1.3896\n",
      "Epoch 19/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 149ms/step - loss: 0.8051 - root_mean_squared_error: 0.8830 - val_loss: 1.9670 - val_root_mean_squared_error: 1.3936\n",
      "Epoch 20/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 150ms/step - loss: 0.7822 - root_mean_squared_error: 0.8703 - val_loss: 1.9675 - val_root_mean_squared_error: 1.3940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f21f98c1b50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rating = layers.Concatenate()([user_emb, rest_emb])\n",
    "rating = layers.Add()([rating, user_bias, rest_bias])\n",
    "\n",
    "# redusing the first dense layer into 15 neurons and adding a l2 regularization\n",
    "rating = layers.Dense(15, activation='relu',kernel_regularizer=regularizers.l2(1e-3))(rating)\n",
    "# creating a dropout layer\n",
    "rating = layers.Dropout(0.3)(rating)\n",
    "# output layer\n",
    "rating = layers.Dense(1, activation='sigmoid')(rating)\n",
    "#convertion of output rating\n",
    "rating = layers.Lambda(lambda x:x*(max_rating - min_rating) + min_rating)(rating)\n",
    "\n",
    "model_1 = models.Model([user, restaurant], rating)\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile( optimizer='sgd', loss='mse',  metrics=[metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model_1.fit(x=[X_train[:,0], X_train[:,1]], y=y_train,\n",
    "            batch_size=256,\n",
    "            epochs=20, \n",
    "            verbose=1,\n",
    "            validation_data=([X_test[:,0], X_test[:,1]], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The second model has performed worse than the first with a higher rmse score and the model is overfitting the training data i.e it has a good train score but poor validation score.\n",
    "\n",
    "we will try and simplify the model further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 141ms/step - loss: 1.6052 - root_mean_squared_error: 1.2586 - val_loss: 1.9195 - val_root_mean_squared_error: 1.3816\n",
      "Epoch 2/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 133ms/step - loss: 1.1682 - root_mean_squared_error: 1.0758 - val_loss: 1.9942 - val_root_mean_squared_error: 1.4083\n",
      "Epoch 3/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 134ms/step - loss: 1.1277 - root_mean_squared_error: 1.0568 - val_loss: 2.0187 - val_root_mean_squared_error: 1.4170\n",
      "Epoch 4/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 133ms/step - loss: 1.0749 - root_mean_squared_error: 1.0315 - val_loss: 2.0266 - val_root_mean_squared_error: 1.4198\n",
      "Epoch 5/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 133ms/step - loss: 1.0261 - root_mean_squared_error: 1.0076 - val_loss: 2.0196 - val_root_mean_squared_error: 1.4173\n",
      "Epoch 6/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 131ms/step - loss: 0.9996 - root_mean_squared_error: 0.9943 - val_loss: 2.0127 - val_root_mean_squared_error: 1.4149\n",
      "Epoch 7/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 131ms/step - loss: 0.9819 - root_mean_squared_error: 0.9854 - val_loss: 2.0153 - val_root_mean_squared_error: 1.4158\n",
      "Epoch 8/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 132ms/step - loss: 0.9672 - root_mean_squared_error: 0.9779 - val_loss: 2.0235 - val_root_mean_squared_error: 1.4187\n",
      "Epoch 9/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 130ms/step - loss: 0.9527 - root_mean_squared_error: 0.9705 - val_loss: 2.0196 - val_root_mean_squared_error: 1.4173\n",
      "Epoch 10/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 131ms/step - loss: 0.9368 - root_mean_squared_error: 0.9622 - val_loss: 2.0274 - val_root_mean_squared_error: 1.4200\n",
      "Epoch 11/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 132ms/step - loss: 0.9351 - root_mean_squared_error: 0.9614 - val_loss: 2.0260 - val_root_mean_squared_error: 1.4196\n",
      "Epoch 12/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 131ms/step - loss: 0.9181 - root_mean_squared_error: 0.9525 - val_loss: 2.0289 - val_root_mean_squared_error: 1.4206\n",
      "Epoch 13/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 132ms/step - loss: 0.9169 - root_mean_squared_error: 0.9519 - val_loss: 2.0294 - val_root_mean_squared_error: 1.4208\n",
      "Epoch 14/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 132ms/step - loss: 0.9117 - root_mean_squared_error: 0.9491 - val_loss: 2.0364 - val_root_mean_squared_error: 1.4232\n",
      "Epoch 15/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 137ms/step - loss: 0.9107 - root_mean_squared_error: 0.9486 - val_loss: 2.0373 - val_root_mean_squared_error: 1.4235\n",
      "Epoch 16/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 130ms/step - loss: 0.8983 - root_mean_squared_error: 0.9420 - val_loss: 2.0377 - val_root_mean_squared_error: 1.4237\n",
      "Epoch 17/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 131ms/step - loss: 0.8937 - root_mean_squared_error: 0.9396 - val_loss: 2.0325 - val_root_mean_squared_error: 1.4218\n",
      "Epoch 18/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 131ms/step - loss: 0.8919 - root_mean_squared_error: 0.9386 - val_loss: 2.0342 - val_root_mean_squared_error: 1.4224\n",
      "Epoch 19/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 133ms/step - loss: 0.8839 - root_mean_squared_error: 0.9343 - val_loss: 2.0392 - val_root_mean_squared_error: 1.4242\n",
      "Epoch 20/20\n",
      "\u001b[1m1673/1673\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 132ms/step - loss: 0.8778 - root_mean_squared_error: 0.9310 - val_loss: 2.0367 - val_root_mean_squared_error: 1.4233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f22018e22d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rating = layers.Concatenate()([user_emb, rest_emb])\n",
    "# Adds the user and restaurant embedding to the dot product of the embeddings\n",
    "rating = layers.Add()([rating, user_bias, rest_bias])\n",
    "\n",
    "# reducing the first layer further to 10 node\n",
    "rating = layers.Dense(10, activation='relu')(rating)\n",
    "# increasing the dropout rate to 0.2\n",
    "rating = layers.Dropout(0.6)(rating)\n",
    "# output layer\n",
    "rating = layers.Dense(1, activation='sigmoid')(rating)\n",
    "# conertion of output rating\n",
    "rating = layers.Lambda(lambda x:x*(max_rating - min_rating) + min_rating)(rating)\n",
    "\n",
    "model_2 = models.Model([user, restaurant], rating)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile( optimizer= 'sgd',\n",
    "                loss='mse', \n",
    "                metrics= [metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model_2.fit(x=[X_train[:,0], X_train[:,1]], y=y_train,\n",
    "            batch_size=256, \n",
    "            epochs=20, \n",
    "            verbose=1,\n",
    "            validation_data=([X_test[:,0], X_test[:,1]], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The third model has further overfitted the training data as it has high validation score and low training score.\n",
    "Therefore our best neural model is baseline model which has a validation score of 1.3179."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "\u001b[1m13380/13380\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 27ms/step - loss: 1.1958 - root_mean_squared_error: 1.0885\n",
      "[1.1989389657974243, 1.089964509010315]\n",
      "Testing data: \n",
      "\u001b[1m3345/3345\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 27ms/step - loss: 1.7751 - root_mean_squared_error: 1.3282\n",
      "[1.779281497001648, 1.3298012018203735]\n"
     ]
    }
   ],
   "source": [
    "# evaluating the best model on the training data\n",
    "print(\"Training data: \")\n",
    "print(baseline_model.evaluate([X_train[:,0], X_train[:,1]], y_train))\n",
    "\n",
    "# evaluating the best model on the test data\n",
    "print(\"Testing data: \")\n",
    "print(baseline_model.evaluate([X_test[:,0], X_test[:,1]], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "***\n",
    "\n",
    "> The baseline model has a training RMSE of 1.1635 and a test RMSE of 1.302 hence being our better neural networks model with the lowest test scores.\n",
    "\n",
    "> In all the models SVD has emerged to be the best RMSE score of 0.068"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python keras-env",
   "language": "python",
   "name": "keras-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
