{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL EVALUATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This section provides a detailed comparative analysis of the models based on their performance metrics. The primary goal is to develop and deploy a robust restaurant recommender system to help customers find the best dining experience.\n",
    "\n",
    "\n",
    "In this project, we will concentrate on three specific types of recommendation models:\n",
    "\n",
    "- Content-Based Recommender Systems\n",
    "\n",
    "\n",
    "- Collaborative Filtering Systems\n",
    "\n",
    "\n",
    "- Deep Neural Networks\n",
    "\n",
    "\n",
    "Within each category, we will evaluate and compare different models to determine which performs the best. For validation and comparison, we will use the RMSE (root mean squared error) metric to measure how closely the predictions align with the actual values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTENT BASED MODELS\n",
    "\n",
    "\n",
    "#### 1) Baseline model - SVD\n",
    "\n",
    "**Vanilla model**\n",
    "\n",
    "The findings for the vanilla SVD include:\n",
    "\n",
    "- **Model Performance Consistency**: The RMSE values across the five cross-validation folds are very close, ranging from 1.213 to 1.220. This indicates that the SVD model is performing consistently, with minimal variation in prediction accuracy across different subsets of the data.\n",
    "\n",
    "\n",
    "\n",
    "- **Average Model Accuracy**: The mean RMSE of 1.217 suggests that, on average, the model's predictions are approximately 1.217 units away from the true values. While this provides a baseline for model accuracy, further tuning or alternative models might be explored to reduce this error.\n",
    "\n",
    "\n",
    "\n",
    "- **Error Analysis with MAE**: The Mean Absolute Error (MAE) values, ranging from 0.946 to 0.950, confirm that the average absolute error is less than 1 unit. MAE complements RMSE by offering a straightforward interpretation of prediction accuracy without heavily penalizing larger errors.\n",
    "\n",
    "\n",
    "\n",
    "- **Training Time Variability**: The fit times for the five folds vary significantly, from around 8.37 to 16.70 seconds. This variability could be due to computational resource differences or data partitioning, but it generally suggests that the model is not computationally expensive to train.\n",
    "\n",
    "\n",
    "\n",
    "- **Efficient Prediction**: The test times are relatively low, with the longest time being just over 2 seconds. This indicates that once the model is trained, it can make predictions quickly, making it suitable for real-time or near-real-time recommendation tasks.\n",
    "\n",
    "\n",
    "The model is however displaying a few shortcomings including:\n",
    "\n",
    "- **Moderate RMSE**: The mean RMSE of 1.217 indicates that the predictions are moderately accurate, but there may still be room for improvement. Exploring different models or fine-tuning the SVD parameters could potentially reduce this error.\n",
    "\n",
    "\n",
    "- **Fit Time Variability**: The significant variation in training times (ranging from 8.37 to 16.70 seconds) could be a concern in scenarios where consistent training time is critical. This variability might indicate that the model's performance could be impacted by differences in data partitioning or computational resources.\n",
    "\n",
    "\n",
    "- **Potential Overfitting**: The cross-validation results are consistent, but without additional checks (like testing on a completely separate validation set), there's a slight risk of overfitting, especially if the model is overly tailored to the specific folds used in cross-validation.\n",
    "\n",
    "\n",
    "To adress these shortcomings,we carry out  hyperparameter tuning for the SVD model using GridSearchCV. It defines a parameter grid with different values for latent factors and regularization terms. GridSearchCV is then used to evaluate these parameters across the dataset to find the best combination. The model is fitted with the dataset to determine the optimal hyperparameters that yield the best performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuned model**\n",
    "\n",
    "The observations for the tuned model include:\n",
    "\n",
    "- Minimal Improvement: The best RMSE after hyperparameter tuning (1.2171) is very close to the initial mean RMSE of 1.2170, indicating that the tuning provided only a slight improvement. This suggests that the model's performance might be close to its maximum potential for this specific dataset and approach.\n",
    "\n",
    "\n",
    "- Higher Complexity: The optimal number of factors (n_factors = 100) is on the higher end of the tested range, which could imply that the model benefits from increased complexity, capturing more intricate patterns in the data.\n",
    "\n",
    "\n",
    "- Low Regularization: The best regularization term (reg_all = 0.02) is relatively low, indicating that the model performs better with less penalty on the size of the coefficients. This may suggest that the model is less prone to overfitting on this dataset.\n",
    "\n",
    "\n",
    "In conclusion,the hyperparameter tuning has fine-tuned the SVD model slightly, but the improvement in performance is minimal. It may be beneficial to explore other models or more advanced feature engineering to achieve more significant gains.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Deep Neural Networks (DNN)\n",
    "\n",
    "We will employ a Keras deep neural network to develop a recommendation system, aiming to enhance our RMSE scores through the use of neural network techniques.\n",
    "\n",
    "**Vanilla model**\n",
    "\n",
    "The Keras code defines a deep neural network for a recommendation system with a three-layer architecture: the first dense layer has 30 nodes with ReLU activation, the second dense layer has 15 nodes with ReLU activation, and the output layer has one node with a sigmoid activation to produce ratings between 0 and 1. A Lambda layer scales these predictions to a range of 1 to 5. The model is compiled using SGD optimizer, MSE loss function, and RMSE as a metric. It is trained on X_train and y_train, with validation on X_test and y_test, for 10 epochs with a batch size of 256.\n",
    "\n",
    "Here’s a summary of the model training results over 10 epochs:\n",
    "\n",
    "- Epoch 1: Initial RMSE is 1.5015 with a validation RMSE of 1.5007. The training loss is 2.2653.\n",
    "\n",
    "- Epoch 2-4: RMSE improves slightly to 1.4983 in epoch 2, and remains stable around 1.4998 to 1.5011 in subsequent epochs. The validation RMSE also stabilizes around 1.5002 to 1.5005.\n",
    "\n",
    "- Epoch 5-7: Further improvement is observed with RMSE decreasing to 1.4994 by epoch 5 and to 1.4993 by epoch 7. The validation RMSE decreases to 1.4980.\n",
    "\n",
    "- Epoch 8-10: Significant improvement is seen with RMSE dropping to 1.4950 by epoch 8, and further decreasing to 1.4780 by epoch 9. By epoch 10, RMSE reaches 1.4409, with the validation RMSE at 1.4512.\n",
    "\n",
    "I conclusion, the model shows a gradual improvement in RMSE and validation RMSE throughout the epochs, with the most significant gains occurring in the later epochs.\n",
    "\n",
    "\n",
    "**Tuned model 1**\n",
    "\n",
    "The model first concatenates user and restaurant embeddings, then adds bias terms before passing the result through a dense layer with 15 neurons and L2 regularization to help prevent overfitting. A dropout layer with a rate of 0.3 is applied to further mitigate overfitting. The output layer uses a sigmoid activation to generate ratings between 0 and 1, which are then scaled to the range between min_rating and max_rating. The model is compiled with the SGD optimizer and MSE loss, evaluating performance using RMSE. It is trained for 20 epochs with a batch size of 256, and validation is conducted on X_test and y_test.\n",
    "\n",
    "Here’s a summary of the training results for the deep neural network model over 20 epochs:\n",
    "\n",
    "- Epoch 1: The initial training RMSE is 1.4413, and validation RMSE is 1.4232, indicating the model is starting to learn.\n",
    "\n",
    "- Epoch 5: Training RMSE improves to 1.1802, while validation RMSE is 1.3785, showing progress in reducing error.\n",
    "\n",
    "- Epoch 10: The model's RMSE is 1.0074 for training and 1.3851 for validation, indicating a reduction in training error but some fluctuation in validation performance.\n",
    "\n",
    "- Epoch 15: Training RMSE reaches 0.9267, and validation RMSE is 1.3883, suggesting the model is learning well but validation error shows some instability.\n",
    "\n",
    "- Epoch 20: Final training RMSE is 0.8703, with a validation RMSE of 1.3940, reflecting a good fit on training data but slight overfitting or instability on validation data.\n",
    "\n",
    "\n",
    "**Tuned model 2**\n",
    "\n",
    "The model concatenates user and restaurant embeddings and adds bias terms before passing the result through a dense layer with 10 neurons and ReLU activation. A dropout layer with a 0.6 rate is used to prevent overfitting. The output layer, with a sigmoid activation, produces ratings between 0 and 1, which are then scaled to the desired rating range. The model is compiled using the SGD optimizer and MSE loss, and it is trained for 20 epochs with a batch size of 256, validated on X_test and y_test.\n",
    "\n",
    "Here’s a summary of the training results for the new model:\n",
    "\n",
    "- Initial Performance: At the beginning of training, the model had a root mean squared error (RMSE) of 1.2586 on the training set and 1.3816 on the validation set.\n",
    "\n",
    "- Improvement Trend: RMSE steadily improved over epochs, reaching 0.9310 on the training set by epoch 20, but the validation RMSE remained relatively high at 1.4233.\n",
    "\n",
    "- Validation Performance: The validation loss and RMSE showed less improvement compared to the training set, indicating potential overfitting or issues with generalization.\n",
    "\n",
    "- Dropout Effect: Despite increasing the dropout rate to 0.6, which typically helps with regularization, the model did not significantly outperform earlier versions, suggesting the need for additional tuning or adjustments.\n",
    "\n",
    "- Epoch Duration: Each epoch took around 220 to 270 seconds to complete, with a slight increase in training time towards the end, likely due to the model complexity and size of the dataset.\n",
    "\n",
    "In conclusion,the third model has further overfitted the training data as it has high validation score and low training score.\n",
    "Therefore our best neural model is baseline model which has a validation score of 1.3179.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the SVD and the best peforming DNN\n",
    "\n",
    "- **Initial Performance**: The DNN starts with a higher RMSE of 1.5015 compared to the SVD model's mean RMSE of 1.217, indicating the DNN requires training to optimize.\n",
    "\n",
    "\n",
    "- **Improvement Over Time**: The DNN shows a notable reduction in RMSE, ending at 1.4409 by epoch 10, yet this is still higher than the SVD model’s best RMSE of 1.2171.\n",
    "\n",
    "\n",
    "- **Validation Performance**: The validation RMSE for the DNN decreases from 1.5007 to 1.4512, which remains higher than the SVD model's mean RMSE.\n",
    "\n",
    "\n",
    "- **Consistency**: The SVD model's RMSE is consistent across folds, whereas the DNN improves gradually, reflecting learning over epochs.\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Despite improvements, the DNN’s final RMSE is higher than the SVD model's, suggesting that the SVD model performs better with this dataset and may require less tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
